{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jashwanthgadipally/NLP/blob/main/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhfXpiC6wudW",
        "outputId": "669e87c4-a9a1-4e43-a854-a0123a03bf35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 182ms/step - accuracy: 0.7009 - loss: 0.5316 - val_accuracy: 0.8592 - val_loss: 0.3247\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 182ms/step - accuracy: 0.9177 - loss: 0.2125 - val_accuracy: 0.8536 - val_loss: 0.3664\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 208ms/step - accuracy: 0.9640 - loss: 0.1043 - val_accuracy: 0.8460 - val_loss: 0.4175\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 181ms/step - accuracy: 0.9847 - loss: 0.0479 - val_accuracy: 0.8337 - val_loss: 0.6298\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 181ms/step - accuracy: 0.9914 - loss: 0.0293 - val_accuracy: 0.8300 - val_loss: 0.6787\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 30ms/step - accuracy: 0.8296 - loss: 0.6940\n",
            "Test Accuracy: 0.8300\n",
            "Epoch 1/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m181s\u001b[0m 227ms/step - accuracy: 0.7357 - loss: 0.5102 - val_accuracy: 0.8346 - val_loss: 0.3752\n",
            "Epoch 2/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 228ms/step - accuracy: 0.9051 - loss: 0.2466 - val_accuracy: 0.8361 - val_loss: 0.3634\n",
            "Epoch 3/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 226ms/step - accuracy: 0.9487 - loss: 0.1437 - val_accuracy: 0.8462 - val_loss: 0.4119\n",
            "Epoch 4/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 226ms/step - accuracy: 0.9732 - loss: 0.0801 - val_accuracy: 0.8322 - val_loss: 0.4932\n",
            "Epoch 5/5\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 223ms/step - accuracy: 0.9803 - loss: 0.0573 - val_accuracy: 0.8304 - val_loss: 0.5772\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - accuracy: 0.8277 - loss: 0.5910\n",
            "LSTM Test Accuracy: 0.8304\n",
            "GRU Test Accuracy: 0.8300\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load data\n",
        "max_features = 20000\n",
        "max_length = 100  # maximum length of each review\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "# Pad sequences to ensure uniform input size\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n",
        "\n",
        "# Convert labels to categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Embedding, Dropout\n",
        "\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_length))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))  # 2 classes for sentiment analysis\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "gru_model = build_gru_model()\n",
        "history = gru_model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test))\n",
        "# Placeholder for text generation (conceptual)\n",
        "# You would typically use a trained model and a seed input to generate text.\n",
        "loss, accuracy = gru_model.evaluate(x_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_length))\n",
        "    model.add(LSTM(128, return_sequences=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lstm_model = build_lstm_model()\n",
        "history_lstm = lstm_model.fit(x_train, y_train, batch_size=32, epochs=5, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate LSTM Model\n",
        "loss_lstm, accuracy_lstm = lstm_model.evaluate(x_test, y_test)\n",
        "print(f'LSTM Test Accuracy: {accuracy_lstm:.4f}')\n",
        "print(f'GRU Test Accuracy: {accuracy:.4f}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz2bSQkPvoAmn87OYlwoe9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}